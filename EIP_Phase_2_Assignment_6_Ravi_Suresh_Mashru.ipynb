{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EIP Phase 2 Assignment 6 - Ravi Suresh Mashru.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mashruravi/eip-notes/blob/master/EIP_Phase_2_Assignment_6_Ravi_Suresh_Mashru.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWBKiDqfP87e",
        "colab_type": "text"
      },
      "source": [
        "# Generating Text from Sherlock Holmes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFV3gCtaeS-s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "e9ec3630-1d1b-4e7a-e6bd-b6a933bf392a"
      },
      "source": [
        "!pip install tensorflow-gpu==1.13.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==1.13.1 in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.33.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (3.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.16.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1) (41.0.1)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu==1.13.1) (3.0.5)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9H2NovRfuot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout, InputLayer\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5RnVrQmP5o9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the file contents and convert them to lowercase\n",
        "filename = 'wonderland.txt'\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()\n",
        "\n",
        "# Replace newline characters with space\n",
        "raw_text = re.sub('\\n', ' ', raw_text)\n",
        "\n",
        "# Replace multiple whitespaces with a single one\n",
        "raw_text = re.sub('\\s+', ' ', raw_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAYQeLvGS3ac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a mapping of unique characters to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "chars = list(filter(lambda x: re.search(r'[0-9a-z\\., ]', x), chars))\n",
        "\n",
        "# Create char -> int and int -> char mappings\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL_KIPwQU_Px",
        "colab_type": "code",
        "outputId": "b32db32a-01ab-42c1-c1d6-d2b09b8765d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "chars"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ',\n",
              " ',',\n",
              " '.',\n",
              " '0',\n",
              " '3',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-g6VdveWBCp",
        "colab_type": "code",
        "outputId": "b9981b90-6926-4658-cf25-f6e242754c66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "\n",
        "print('Total characters in text: {}'.format(n_chars))\n",
        "print('Total characters in vocabulary: {}'.format(n_vocab))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total characters in text: 142492\n",
            "Total characters in vocabulary: 31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAR0eh0DwcNV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e0935a36-0351-42df-aaf1-85ae6490ac04"
      },
      "source": [
        "THRESHOLD=20\n",
        "\n",
        "story_lines = raw_text.split('.')\n",
        "\n",
        "# The length of the padded sequences will be the maximum line length\n",
        "max_line_len = max(map(lambda x: len(x), story_lines))\n",
        "print('Max line length: ', max_line_len)\n",
        "\n",
        "sequencesX = []\n",
        "sequencesY = []\n",
        "\n",
        "for story_line in story_lines:\n",
        "  \n",
        "  # Remove special characters from line\n",
        "  all_chars = list(story_line)\n",
        "  valid_chars = [c for c in all_chars if c in chars]\n",
        "  \n",
        "  # Ignore lines that have length less than THRESHOLD\n",
        "  if len(valid_chars) > THRESHOLD:\n",
        "    valid_chars_int=[char_to_int[c] for c in valid_chars]\n",
        "    for i in range(len(valid_chars_int)-1):\n",
        "      sequencesX.append(valid_chars_int[:i+1])\n",
        "      sequencesY.append(valid_chars_int[i+1])\n",
        "      \n",
        "\n",
        "# Pad sequences in sequencesX with maximum line length  \n",
        "dataX = pad_sequences(sequencesX, maxlen=max_line_len)\n",
        "dataY = [[x] for x in sequencesY]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max line length:  1516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAc5PtQt14Cz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a1c74919-7bad-49f6-ea7c-ebe657ccd7f4"
      },
      "source": [
        "n_patterns = len(dataX)\n",
        "print('Total patterns: {}'.format(n_patterns))\n",
        "\n",
        "# Reshape X to be [batch size, time steps, features] <-- required by LSTM\n",
        "X = numpy.reshape(dataX, (n_patterns, max_line_len, 1))\n",
        "\n",
        "# Scale data to be between 0 and 1\n",
        "X = X / float(n_vocab)\n",
        "\n",
        "# One-hot encode the output\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total patterns: 135228\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etjvn3l3EwTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF-yhZ7vY6ZR",
        "colab_type": "code",
        "outputId": "2cad637c-60d0-4b60-a721-0f9b6c3e7b85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "# Create a model\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(LSTM(512, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "import os\n",
        "import tensorflow\n",
        "\n",
        "tpu_model = tensorflow.contrib.tpu.keras_to_tpu_model(\n",
        "  model,\n",
        "  strategy=tensorflow.contrib.tpu.TPUDistributionStrategy(\n",
        "    tensorflow.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "  )\n",
        ")\n",
        "\n",
        "tpu_model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.6.233.18:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 3220007950122983503)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 6243412164784341985)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 11512458664191658974)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 5876125204348917811)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 16335538802777417544)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 14381089803709528841)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 2134881121819182120)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 11407071995151818373)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6915917969628586374)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 103256834063532532)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 9897602913123904523)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON7s5lj6j8FN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checkpoint to save the best model\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK8FJ3Uwahbh",
        "colab_type": "code",
        "outputId": "f14dc5af-aeac-4f7e-c7a7-a24dcf0e2636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tpu_model.fit(X_train, y_train, epochs=20, batch_size=128, validation_data=[X_val, y_val], callbacks=callbacks_list)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 114943 samples, validate on 20285 samples\n",
            "Epoch 1/20\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id_20'), TensorSpec(shape=(16, 1516, 1), dtype=tf.float32, name='input_2_10'), TensorSpec(shape=(16, 31), dtype=tf.float32, name='dense_2_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "INFO:tensorflow:Remapping placeholder for input_2\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7f16cbca6978> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 4.3230369091033936 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "INFO:tensorflow:CPU -> TPU lr: 0.0010000000474974513 {0.001}\n",
            "INFO:tensorflow:CPU -> TPU beta_1: 0.8999999761581421 {0.9}\n",
            "INFO:tensorflow:CPU -> TPU beta_2: 0.9990000128746033 {0.999}\n",
            "INFO:tensorflow:CPU -> TPU decay: 0.0 {0.0}\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114688/114943 [============================>.] - ETA: 0s - loss: 2.8159INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(15,), dtype=tf.int32, name='core_id_20'), TensorSpec(shape=(15, 1516, 1), dtype=tf.float32, name='input_2_10'), TensorSpec(shape=(15, 31), dtype=tf.float32, name='dense_2_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_2\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7f16cbca6978> [<tf.Variable 'tpu_139735890409288/Adam/iterations:0' shape=() dtype=int64>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f16cac975f8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f16cac97f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f16cacbb3c8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f16cac76ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f16cabbe780>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f16cab82e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f16cab71ba8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f16cab394a8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f16caafdda0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f16caa43780>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f16caa0cb38>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f16ca9d0b70>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f16ca9bccf8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f16ca90acc0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f16ca8d1860>]\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 4.620448112487793 secs\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.8157INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(16,), dtype=tf.int32, name='core_id_30'), TensorSpec(shape=(16, 1516, 1), dtype=tf.float32, name='input_2_10'), TensorSpec(shape=(16, 31), dtype=tf.float32, name='dense_2_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "INFO:tensorflow:Remapping placeholder for input_2\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7f16c91bbac8> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 4.257609605789185 secs\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(7,), dtype=tf.int32, name='core_id_30'), TensorSpec(shape=(7, 1516, 1), dtype=tf.float32, name='input_2_10'), TensorSpec(shape=(7, 31), dtype=tf.float32, name='dense_2_target_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_2\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7f16c91bbac8> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 2.36287784576416 secs\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.81557, saving model to weights-improvement-01-2.8156.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 291s 3ms/sample - loss: 2.8156 - val_loss: 2.7182\n",
            "Epoch 2/20\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.7394\n",
            "Epoch 00002: loss improved from 2.81557 to 2.73940, saving model to weights-improvement-02-2.7394.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 252s 2ms/sample - loss: 2.7394 - val_loss: 2.8493\n",
            "Epoch 3/20\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.7789\n",
            "Epoch 00003: loss did not improve from 2.73940\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.7788 - val_loss: 3.5730\n",
            "Epoch 4/20\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.8285\n",
            "Epoch 00004: loss did not improve from 2.73940\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.8286 - val_loss: 2.9065\n",
            "Epoch 5/20\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.7656\n",
            "Epoch 00005: loss did not improve from 2.73940\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.7656 - val_loss: 2.9398\n",
            "Epoch 6/20\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.7384\n",
            "Epoch 00006: loss improved from 2.73940 to 2.73845, saving model to weights-improvement-06-2.7385.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 253s 2ms/sample - loss: 2.7385 - val_loss: 2.8769\n",
            "Epoch 7/20\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.7152\n",
            "Epoch 00007: loss improved from 2.73845 to 2.71530, saving model to weights-improvement-07-2.7153.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 252s 2ms/sample - loss: 2.7153 - val_loss: 2.8839\n",
            "Epoch 8/20\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.6940\n",
            "Epoch 00008: loss improved from 2.71530 to 2.69398, saving model to weights-improvement-08-2.6940.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 252s 2ms/sample - loss: 2.6940 - val_loss: 2.7119\n",
            "Epoch 9/20\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.6702\n",
            "Epoch 00009: loss improved from 2.69398 to 2.67046, saving model to weights-improvement-09-2.6705.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 253s 2ms/sample - loss: 2.6705 - val_loss: 2.7506\n",
            "Epoch 10/20\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.6508\n",
            "Epoch 00010: loss improved from 2.67046 to 2.65084, saving model to weights-improvement-10-2.6508.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 252s 2ms/sample - loss: 2.6508 - val_loss: 2.7416\n",
            "Epoch 11/20\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.6358\n",
            "Epoch 00011: loss improved from 2.65084 to 2.63568, saving model to weights-improvement-11-2.6357.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 252s 2ms/sample - loss: 2.6357 - val_loss: 2.7781\n",
            "Epoch 12/20\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.6080\n",
            "Epoch 00012: loss improved from 2.63568 to 2.60809, saving model to weights-improvement-12-2.6081.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 252s 2ms/sample - loss: 2.6081 - val_loss: 2.7508\n",
            "Epoch 13/20\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.6199\n",
            "Epoch 00013: loss did not improve from 2.60809\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.6198 - val_loss: 2.6468\n",
            "Epoch 14/20\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.6028\n",
            "Epoch 00014: loss improved from 2.60809 to 2.60283, saving model to weights-improvement-14-2.6028.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 254s 2ms/sample - loss: 2.6028 - val_loss: 2.6175\n",
            "Epoch 15/20\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.5534\n",
            "Epoch 00015: loss improved from 2.60283 to 2.55347, saving model to weights-improvement-15-2.5535.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 253s 2ms/sample - loss: 2.5535 - val_loss: 2.5444\n",
            "Epoch 16/20\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.5092\n",
            "Epoch 00016: loss improved from 2.55347 to 2.50933, saving model to weights-improvement-16-2.5093.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 253s 2ms/sample - loss: 2.5093 - val_loss: 2.5170\n",
            "Epoch 17/20\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.4674\n",
            "Epoch 00017: loss improved from 2.50933 to 2.46728, saving model to weights-improvement-17-2.4673.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 252s 2ms/sample - loss: 2.4673 - val_loss: 2.5227\n",
            "Epoch 18/20\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.4205\n",
            "Epoch 00018: loss improved from 2.46728 to 2.42057, saving model to weights-improvement-18-2.4206.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 252s 2ms/sample - loss: 2.4206 - val_loss: 2.4593\n",
            "Epoch 19/20\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3721\n",
            "Epoch 00019: loss improved from 2.42057 to 2.37232, saving model to weights-improvement-19-2.3723.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 252s 2ms/sample - loss: 2.3723 - val_loss: 2.4032\n",
            "Epoch 20/20\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3322\n",
            "Epoch 00020: loss improved from 2.37232 to 2.33246, saving model to weights-improvement-20-2.3325.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 252s 2ms/sample - loss: 2.3325 - val_loss: 2.4704\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f16cbeba668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E26OOtMm5knM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "39b59278-a67f-416d-a757-7d31233b2cf9"
      },
      "source": [
        "tpu_model.fit(X_train, y_train, epochs=40, batch_size=128, validation_data=[X_val, y_val], callbacks=callbacks_list)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 114943 samples, validate on 20285 samples\n",
            "Epoch 1/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2966\n",
            "Epoch 00001: loss improved from 2.33246 to 2.29652, saving model to weights-improvement-01-2.2965.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 253s 2ms/sample - loss: 2.2965 - val_loss: 2.4995\n",
            "Epoch 2/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3470\n",
            "Epoch 00002: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.3473 - val_loss: 2.6591\n",
            "Epoch 3/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.6084\n",
            "Epoch 00003: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.6084 - val_loss: 2.5387\n",
            "Epoch 4/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.5193\n",
            "Epoch 00004: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.5193 - val_loss: 2.5101\n",
            "Epoch 5/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.4618\n",
            "Epoch 00005: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.4617 - val_loss: 2.5524\n",
            "Epoch 6/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.4247\n",
            "Epoch 00006: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.4248 - val_loss: 2.5368\n",
            "Epoch 7/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.4019\n",
            "Epoch 00007: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.4019 - val_loss: 2.5347\n",
            "Epoch 8/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3822\n",
            "Epoch 00008: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.3823 - val_loss: 2.5110\n",
            "Epoch 9/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3991\n",
            "Epoch 00009: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.3992 - val_loss: 2.5381\n",
            "Epoch 10/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3755\n",
            "Epoch 00010: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.3755 - val_loss: 2.4651\n",
            "Epoch 11/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3609\n",
            "Epoch 00011: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.3608 - val_loss: 2.4128\n",
            "Epoch 12/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3550\n",
            "Epoch 00012: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 245s 2ms/sample - loss: 2.3551 - val_loss: 2.4145\n",
            "Epoch 13/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3468\n",
            "Epoch 00013: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.3468 - val_loss: 2.4193\n",
            "Epoch 14/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3447\n",
            "Epoch 00014: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.3447 - val_loss: 2.4350\n",
            "Epoch 15/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3410\n",
            "Epoch 00015: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.3411 - val_loss: 2.4106\n",
            "Epoch 16/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3370\n",
            "Epoch 00016: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.3370 - val_loss: 2.3822\n",
            "Epoch 17/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3358\n",
            "Epoch 00017: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.3359 - val_loss: 2.3490\n",
            "Epoch 18/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3312\n",
            "Epoch 00018: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.3313 - val_loss: 2.3508\n",
            "Epoch 19/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3324\n",
            "Epoch 00019: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.3324 - val_loss: 2.4104\n",
            "Epoch 20/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3304\n",
            "Epoch 00020: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.3303 - val_loss: 2.3991\n",
            "Epoch 21/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3249\n",
            "Epoch 00021: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.3248 - val_loss: 2.3901\n",
            "Epoch 22/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3210\n",
            "Epoch 00022: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.3209 - val_loss: 2.3997\n",
            "Epoch 23/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3194\n",
            "Epoch 00023: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.3194 - val_loss: 2.4386\n",
            "Epoch 24/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3160\n",
            "Epoch 00024: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.3159 - val_loss: 2.3625\n",
            "Epoch 25/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3113\n",
            "Epoch 00025: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.3112 - val_loss: 2.3956\n",
            "Epoch 26/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3126\n",
            "Epoch 00026: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.3125 - val_loss: 2.4152\n",
            "Epoch 27/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3136\n",
            "Epoch 00027: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.3138 - val_loss: 2.3542\n",
            "Epoch 28/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3093\n",
            "Epoch 00028: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.3093 - val_loss: 2.3742\n",
            "Epoch 29/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3131\n",
            "Epoch 00029: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.3130 - val_loss: 2.3810\n",
            "Epoch 30/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3110\n",
            "Epoch 00030: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.3110 - val_loss: 2.3727\n",
            "Epoch 31/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3133\n",
            "Epoch 00031: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.3134 - val_loss: 2.4251\n",
            "Epoch 32/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3058\n",
            "Epoch 00032: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.3059 - val_loss: 2.3878\n",
            "Epoch 33/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2989\n",
            "Epoch 00033: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.2991 - val_loss: 2.3612\n",
            "Epoch 34/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.3017\n",
            "Epoch 00034: loss did not improve from 2.29652\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.3016 - val_loss: 2.3589\n",
            "Epoch 35/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2921\n",
            "Epoch 00035: loss improved from 2.29652 to 2.29192, saving model to weights-improvement-35-2.2919.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 253s 2ms/sample - loss: 2.2919 - val_loss: 2.3371\n",
            "Epoch 36/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2921\n",
            "Epoch 00036: loss did not improve from 2.29192\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.2921 - val_loss: 2.3539\n",
            "Epoch 37/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2884\n",
            "Epoch 00037: loss improved from 2.29192 to 2.28841, saving model to weights-improvement-37-2.2884.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 253s 2ms/sample - loss: 2.2884 - val_loss: 2.3271\n",
            "Epoch 38/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2875\n",
            "Epoch 00038: loss improved from 2.28841 to 2.28736, saving model to weights-improvement-38-2.2874.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 253s 2ms/sample - loss: 2.2874 - val_loss: 2.3255\n",
            "Epoch 39/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2870\n",
            "Epoch 00039: loss improved from 2.28736 to 2.28686, saving model to weights-improvement-39-2.2869.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 253s 2ms/sample - loss: 2.2869 - val_loss: 2.3129\n",
            "Epoch 40/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2846\n",
            "Epoch 00040: loss improved from 2.28686 to 2.28421, saving model to weights-improvement-40-2.2842.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 254s 2ms/sample - loss: 2.2842 - val_loss: 2.3088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f16c86c9da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdE8PQK4AN5W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "06a3acd3-9000-433d-f0d2-e6c04a4c8ebc"
      },
      "source": [
        "tpu_model.fit(X_train, y_train, epochs=40, batch_size=128, validation_data=[X_val, y_val], callbacks=callbacks_list)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 114943 samples, validate on 20285 samples\n",
            "Epoch 1/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2823\n",
            "Epoch 00001: loss improved from 2.28421 to 2.28251, saving model to weights-improvement-01-2.2825.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 254s 2ms/sample - loss: 2.2825 - val_loss: 2.3185\n",
            "Epoch 2/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2815\n",
            "Epoch 00002: loss improved from 2.28251 to 2.28156, saving model to weights-improvement-02-2.2816.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 254s 2ms/sample - loss: 2.2816 - val_loss: 2.3119\n",
            "Epoch 3/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2793\n",
            "Epoch 00003: loss improved from 2.28156 to 2.27931, saving model to weights-improvement-03-2.2793.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 254s 2ms/sample - loss: 2.2793 - val_loss: 2.3050\n",
            "Epoch 4/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2766\n",
            "Epoch 00004: loss improved from 2.27931 to 2.27649, saving model to weights-improvement-04-2.2765.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 253s 2ms/sample - loss: 2.2765 - val_loss: 2.2982\n",
            "Epoch 5/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2739\n",
            "Epoch 00005: loss improved from 2.27649 to 2.27385, saving model to weights-improvement-05-2.2739.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 253s 2ms/sample - loss: 2.2739 - val_loss: 2.3307\n",
            "Epoch 6/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2688\n",
            "Epoch 00006: loss improved from 2.27385 to 2.26874, saving model to weights-improvement-06-2.2687.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 253s 2ms/sample - loss: 2.2687 - val_loss: 2.3292\n",
            "Epoch 7/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2734\n",
            "Epoch 00007: loss did not improve from 2.26874\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.2733 - val_loss: 2.3141\n",
            "Epoch 8/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2728\n",
            "Epoch 00008: loss did not improve from 2.26874\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.2727 - val_loss: 2.3230\n",
            "Epoch 9/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2759\n",
            "Epoch 00009: loss did not improve from 2.26874\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.2758 - val_loss: 2.3357\n",
            "Epoch 10/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2740\n",
            "Epoch 00010: loss did not improve from 2.26874\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.2739 - val_loss: 2.3077\n",
            "Epoch 11/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2730\n",
            "Epoch 00011: loss did not improve from 2.26874\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.2728 - val_loss: 2.3346\n",
            "Epoch 12/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2727\n",
            "Epoch 00012: loss did not improve from 2.26874\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.2728 - val_loss: 2.2820\n",
            "Epoch 13/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2745\n",
            "Epoch 00013: loss did not improve from 2.26874\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.2745 - val_loss: 2.3163\n",
            "Epoch 14/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2707\n",
            "Epoch 00014: loss did not improve from 2.26874\n",
            "114943/114943 [==============================] - 243s 2ms/sample - loss: 2.2708 - val_loss: 2.2905\n",
            "Epoch 15/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2702\n",
            "Epoch 00015: loss did not improve from 2.26874\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.2702 - val_loss: 2.3037\n",
            "Epoch 16/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2703\n",
            "Epoch 00016: loss did not improve from 2.26874\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.2701 - val_loss: 2.3216\n",
            "Epoch 17/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2673\n",
            "Epoch 00017: loss improved from 2.26874 to 2.26728, saving model to weights-improvement-17-2.2673.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 253s 2ms/sample - loss: 2.2673 - val_loss: 2.3143\n",
            "Epoch 18/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2648\n",
            "Epoch 00018: loss improved from 2.26728 to 2.26482, saving model to weights-improvement-18-2.2648.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 254s 2ms/sample - loss: 2.2648 - val_loss: 2.3273\n",
            "Epoch 19/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2665\n",
            "Epoch 00019: loss did not improve from 2.26482\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.2666 - val_loss: 2.3360\n",
            "Epoch 20/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2646\n",
            "Epoch 00020: loss did not improve from 2.26482\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.2649 - val_loss: 2.3299\n",
            "Epoch 21/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2598\n",
            "Epoch 00021: loss improved from 2.26482 to 2.25969, saving model to weights-improvement-21-2.2597.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 254s 2ms/sample - loss: 2.2597 - val_loss: 2.3215\n",
            "Epoch 22/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2597\n",
            "Epoch 00022: loss improved from 2.25969 to 2.25950, saving model to weights-improvement-22-2.2595.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 254s 2ms/sample - loss: 2.2595 - val_loss: 2.3018\n",
            "Epoch 23/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2578\n",
            "Epoch 00023: loss improved from 2.25950 to 2.25775, saving model to weights-improvement-23-2.2578.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 254s 2ms/sample - loss: 2.2578 - val_loss: 2.3260\n",
            "Epoch 24/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2563\n",
            "Epoch 00024: loss improved from 2.25775 to 2.25625, saving model to weights-improvement-24-2.2563.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 254s 2ms/sample - loss: 2.2563 - val_loss: 2.3231\n",
            "Epoch 25/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2557\n",
            "Epoch 00025: loss improved from 2.25625 to 2.25567, saving model to weights-improvement-25-2.2557.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 254s 2ms/sample - loss: 2.2557 - val_loss: 2.3185\n",
            "Epoch 26/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2475\n",
            "Epoch 00026: loss improved from 2.25567 to 2.24759, saving model to weights-improvement-26-2.2476.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 255s 2ms/sample - loss: 2.2476 - val_loss: 2.3422\n",
            "Epoch 27/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2484\n",
            "Epoch 00027: loss did not improve from 2.24759\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.2483 - val_loss: 2.3866\n",
            "Epoch 28/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2498\n",
            "Epoch 00028: loss did not improve from 2.24759\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.2498 - val_loss: 2.3414\n",
            "Epoch 29/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2467\n",
            "Epoch 00029: loss improved from 2.24759 to 2.24686, saving model to weights-improvement-29-2.2469.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 254s 2ms/sample - loss: 2.2469 - val_loss: 2.3057\n",
            "Epoch 30/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2446\n",
            "Epoch 00030: loss improved from 2.24686 to 2.24449, saving model to weights-improvement-30-2.2445.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 254s 2ms/sample - loss: 2.2445 - val_loss: 2.2932\n",
            "Epoch 31/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2448\n",
            "Epoch 00031: loss did not improve from 2.24449\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.2451 - val_loss: 2.3129\n",
            "Epoch 32/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2484\n",
            "Epoch 00032: loss did not improve from 2.24449\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.2484 - val_loss: 2.3124\n",
            "Epoch 33/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2401\n",
            "Epoch 00033: loss improved from 2.24449 to 2.24015, saving model to weights-improvement-33-2.2402.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 254s 2ms/sample - loss: 2.2402 - val_loss: 2.3269\n",
            "Epoch 34/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2381\n",
            "Epoch 00034: loss improved from 2.24015 to 2.23816, saving model to weights-improvement-34-2.2382.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 254s 2ms/sample - loss: 2.2382 - val_loss: 2.3566\n",
            "Epoch 35/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2378\n",
            "Epoch 00035: loss improved from 2.23816 to 2.23796, saving model to weights-improvement-35-2.2380.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 254s 2ms/sample - loss: 2.2380 - val_loss: 2.3466\n",
            "Epoch 36/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2387\n",
            "Epoch 00036: loss did not improve from 2.23796\n",
            "114943/114943 [==============================] - 244s 2ms/sample - loss: 2.2387 - val_loss: 2.3248\n",
            "Epoch 37/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2377\n",
            "Epoch 00037: loss improved from 2.23796 to 2.23763, saving model to weights-improvement-37-2.2376.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 254s 2ms/sample - loss: 2.2376 - val_loss: 2.3490\n",
            "Epoch 38/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2362\n",
            "Epoch 00038: loss improved from 2.23763 to 2.23607, saving model to weights-improvement-38-2.2361.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 254s 2ms/sample - loss: 2.2361 - val_loss: 2.3454\n",
            "Epoch 39/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2357\n",
            "Epoch 00039: loss improved from 2.23607 to 2.23563, saving model to weights-improvement-39-2.2356.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 254s 2ms/sample - loss: 2.2356 - val_loss: 2.3595\n",
            "Epoch 40/40\n",
            "114816/114943 [============================>.] - ETA: 0s - loss: 2.2337\n",
            "Epoch 00040: loss improved from 2.23563 to 2.23364, saving model to weights-improvement-40-2.2336.hdf5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "114943/114943 [==============================] - 254s 2ms/sample - loss: 2.2336 - val_loss: 2.3898\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f16c821a550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrxWUK0Nm1Nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "model.load_weights('weights-improvement-40-2.2336.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnquYE3P2Rwg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "43258644-42a2-4141-b781-548829f179ee"
      },
      "source": [
        "# Create seed text\n",
        "seed_text='once upon a time'\n",
        "\n",
        "# Convert seed text to integers\n",
        "seed_text_int=[char_to_int[x] for x in seed_text]\n",
        "\n",
        "# Pad the seed text\n",
        "padded_seed=pad_sequences([seed_text_int], maxlen=max_line_len)\n",
        "\n",
        "# Predict 500 characters\n",
        "pattern = padded_seed[0]\n",
        "predicted_text = ''\n",
        "for i in range(500):\n",
        "  x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "  x = x / float(n_vocab)\n",
        "  prediction = model.predict(x, batch_size=8)\n",
        "  index = numpy.argmax(prediction)\n",
        "  result = int_to_char[index]\n",
        "  predicted_text+=result\n",
        "  pattern = numpy.append(pattern[1:], [index])\n",
        "  \n",
        "print(seed_text, predicted_text)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "once upon a time  to he the todee the woole the was  od the wooder whet iar he  oo  he  oe the aoa sand ehr the war a lott  he the woocer whet ian eere and the was a  ie the wooder taid the hotse  nu wo  ae io a lott  he a  ie to  e d toeale  oe the was a  a  ie a taid the was a  a  i  and the said the had and e  ane the tooe of the taid the ho   ne the aod e dou soeeze a  ie the wesy onteen a  ie the woode the wod th  noc to  ena the toog the thb ooce turel e  and the was a  a  i  and the wooder a              \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}